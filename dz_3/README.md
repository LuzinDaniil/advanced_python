[10 баллов] –азработать web-crawler и поиск дл€ сайта https://docs.python.org (или любого другого контентного)
Crawler должен обходить только ссылки внутри указанного домена.
—качивание ресурсов должно быть реализовано в нескольких параллельных корутинах дл€ достижени€ максимальной скорости обкачки.
—корость обкачки должна быть параметром краулера. Ќапример, 10 rps должно означать, что в секунду должно быть не более 10 запросов на домен.
 ажда€ страница должна быть положена в индекс elasticsearch. ћожно использовать библиотеку aioelasticsearch.

[5 баллов] –азработать api, использу€ aiohttp или sanic, которое будет отдавать результаты поиска

/api/v1/search
ƒолжен принимать следующий параметры
q - текстовый запрос
limit - количество результатов
offset - офсет результатов
¬ ответ должен возвращать список результатов (ссылок на обкачиваемый сайт), отсортированные по релевантности